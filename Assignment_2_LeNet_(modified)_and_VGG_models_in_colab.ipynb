{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "FE9C4kbGnc5o",
    "outputId": "a0617c79-f6c9-45e7-baa8-437aa8586a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting log_progress\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/45/4590ed742f1ba1839be58c4a627993fccdcd875e97d39c388bd9270d5b8e/log_progress-1.1.tar.gz\n",
      "Building wheels for collected packages: log-progress\n",
      "  Building wheel for log-progress (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/yuhuahe/Library/Caches/pip/wheels/7e/5f/15/7dcd1a3459964b0940f840dc9f5402893354ae6c47ceceb8da\n",
      "Successfully built log-progress\n",
      "Installing collected packages: log-progress\n",
      "Successfully installed log-progress-1.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d9ba3963efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# from utils import log_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "!pip install log_progress\n",
    "\n",
    "import glob \n",
    "import numpy as np \n",
    "import os \n",
    "import shutil \n",
    "# from utils import log_progress \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img \n",
    " \n",
    "np.random.seed(42) \n",
    " \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-hgpPJdM0Lv3",
    "outputId": "c2d55655-289e-4375-ddd6-605c5bc09b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'deepLearning'...\n",
      "Host key verification failed.\r\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "pRk1rgN50O4n",
    "outputId": "64a96e4e-09e6-4106-9b79-a84b9cbb01d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQ2uxZrVneBd"
   },
   "outputs": [],
   "source": [
    "files = glob.glob('train/*') \n",
    " \n",
    "cat_files = [fn for fn in files if 'cat' in fn] \n",
    "dog_files = [fn for fn in files if 'dog' in fn] \n",
    "len(cat_files), len(dog_files) \n",
    " \n",
    "Out [3]: (12500, 12500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "L_zSvriJtswK",
    "outputId": "b450402e-565d-4e52-e195-a5b5551518ac"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4fbccf6fb771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdog_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcat_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdog_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "cat_train = np.random.choice(cat_files, size=1500, replace=False) \n",
    "dog_train = np.random.choice(dog_files, size=1500, replace=False) \n",
    "cat_files = list(set(cat_files) - set(cat_train)) \n",
    "dog_files = list(set(dog_files) - set(dog_train)) \n",
    " \n",
    "cat_val = np.random.choice(cat_files, size=500, replace=False) \n",
    "dog_val = np.random.choice(dog_files, size=500, replace=False) \n",
    "cat_files = list(set(cat_files) - set(cat_val)) \n",
    "dog_files = list(set(dog_files) - set(dog_val)) \n",
    " \n",
    "cat_test = np.random.choice(cat_files, size=500, replace=False) \n",
    "dog_test = np.random.choice(dog_files, size=500, replace=False) \n",
    " \n",
    "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape) \n",
    "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "I_-zWR20vd7y",
    "outputId": "10751e6b-7600-4d33-e9d8-d59c71ac857d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = 'training_data' \n",
    "val_dir = 'validation_data' \n",
    "test_dir = 'test_data' \n",
    " \n",
    "train_files = np.concatenate([cat_train, dog_train]) \n",
    "validate_files = np.concatenate([cat_val, dog_val]) \n",
    "test_files = np.concatenate([cat_test, dog_test]) \n",
    " \n",
    "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None \n",
    "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None \n",
    "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None \n",
    " \n",
    "for fn in log_progress(train_files, name='Training Images'): \n",
    "    shutil.copy(fn, train_dir) \n",
    "for fn in log_progress(validate_files, name='Validation Images'): \n",
    "    shutil.copy(fn, val_dir) \n",
    "for fn in log_progress(test_files, name='Test Images'): \n",
    "    shutil.copy(fn, test_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "LJ_8PkqLvrzk",
    "outputId": "ff0e069b-ac81-414a-91ce-409f46d43dd4"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-36032039b159>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    Train dataset shape: (3000, 150, 150, 3)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "IMG_DIM = (150, 150) \n",
    " \n",
    "train_files = glob.glob('training_data/*') \n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img  \n",
    "              in train_files] \n",
    "train_imgs = np.array(train_imgs) \n",
    "train_labels = [fn.split('/')[1].split('.')[0].strip() for fn in \n",
    "                train_files] \n",
    " \n",
    "validation_files = glob.glob('validation_data/*') \n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for \n",
    "                   img in validation_files] \n",
    "validation_imgs = np.array(validation_imgs) \n",
    "validation_labels = [fn.split('/')[1].split('.')[0].strip() for fn in \n",
    "                     validation_files] \n",
    " \n",
    "print('Train dataset shape:', train_imgs.shape,  \n",
    "      'tValidation dataset shape:', validation_imgs.shape) \n",
    " \n",
    " \n",
    "Train dataset shape: (3000, 150, 150, 3)         \n",
    "Validation dataset shape: (1000, 150, 150, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhWOUIwp2Ck_"
   },
   "outputs": [],
   "source": [
    "train_imgs_scaled = train_imgs.astype('float32') \n",
    "validation_imgs_scaled = validation_imgs.astype('float32') \n",
    "train_imgs_scaled /= 255 \n",
    "validation_imgs_scaled /= 255 \n",
    " \n",
    "# visualize a sample image \n",
    "print(train_imgs[0].shape) \n",
    "array_to_img(train_imgs[0]) \n",
    " \n",
    "(150, 150, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZuGxmka2C6y"
   },
   "outputs": [],
   "source": [
    "batch_size = 30 \n",
    "num_classes = 2 \n",
    "epochs = 30 \n",
    "input_shape = (150, 150, 3) \n",
    " \n",
    "# encode text category labels \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    " \n",
    "le = LabelEncoder() \n",
    "le.fit(train_labels) \n",
    "train_labels_enc = le.transform(train_labels) \n",
    "validation_labels_enc = le.transform(validation_labels) \n",
    " \n",
    "print(train_labels[1495:1505], train_labels_enc[1495:1505]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "fIsYcNg-2C-H",
    "outputId": "47cbe001-bcd9-47ca-b03c-1d222ed0ba59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8e5c649b-fa13-43c0-8a21-a6186f172898\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-8e5c649b-fa13-43c0-8a21-a6186f172898\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "MessageError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-72edf3658aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: CustomError: Timed out waiting for iframe configuration. URL: https://colab.research.google.com/drive/1YIaHn4CNP6U_mQtZ8QsktSwkr4QeOEuo#scrollTo=fIsYcNg-2C-H"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers \n",
    " \n",
    "model = Sequential() \n",
    "\n",
    "# convolution and pooling layers \n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',  \n",
    "                 input_shape=input_shape)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    " \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    " \n",
    " \n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(), \n",
    "              metrics=['accuracy']) \n",
    " \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksnHai-S2DBI"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=train_imgs_scaled, y=train_labels_enc, \n",
    "validation_data=(validation_imgs_scaled,    \n",
    "                 validation_labels_enc), \n",
    "                 batch_size=batch_size, \n",
    "                 epochs=epochs, \n",
    "                 verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_MUJrTb2DD6"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4)) \n",
    "t = f.suptitle('Basic CNN Performance', fontsize=12) \n",
    "f.subplots_adjust(top=0.85, wspace=0.3) \n",
    " \n",
    "epoch_list = list(range(1,31)) \n",
    "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy') \n",
    "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy') \n",
    "ax1.set_xticks(np.arange(0, 31, 5)) \n",
    "ax1.set_ylabel('Accuracy Value') \n",
    "ax1.set_xlabel('Epoch') \n",
    "ax1.set_title('Accuracy') \n",
    "l1 = ax1.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuPajqPa2DGu"
   },
   "outputs": [],
   "source": [
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss') \n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss') \n",
    "ax2.set_xticks(np.arange(0, 31, 5)) \n",
    "ax2.set_ylabel('Loss Value') \n",
    "ax2.set_xlabel('Epoch') \n",
    "ax2.set_title('Loss') \n",
    "l2 = ax2.legend(loc=\"best\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peHT53ET2DJq"
   },
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "# convolutional and pooling layers \n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',  \n",
    "                 input_shape=input_shape)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    " \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    " \n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(), \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAmOzZ4F2DMT"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=train_imgs_scaled, y=train_labels_enc, \n",
    "                    validation_data=(validation_imgs_scaled,  \n",
    "                                     validation_labels_enc), \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XD0aYUpD2DPF"
   },
   "outputs": [],
   "source": [
    "model.save('cats_dogs_basic_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnPV-kSh5vBz"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,  \n",
    "                                   rotation_range=50, \n",
    "                                   width_shift_range=0.2,  \n",
    "                                   height_shift_range=0.2,   \n",
    "                                   shear_range=0.2,  \n",
    "                                   horizontal_flip=True,   \n",
    "                                   fill_mode='nearest') \n",
    " \n",
    "val_datagen = ImageDataGenerator(rescale=1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gxJmW5H5vM2"
   },
   "outputs": [],
   "source": [
    "img_id = 1991 \n",
    "dog_generator = train_datagen.flow(train_imgs[img_id:img_id+1],  \n",
    "                                   train_labels[img_id:img_id+1], \n",
    "                                   batch_size=1) \n",
    "dog = [next(dog_generator) for i in range(0,5)] \n",
    "fig, ax = plt.subplots(1,5, figsize=(15, 6)) \n",
    "print('Labels:', [item[1][0] for item in dog]) \n",
    "l = [ax[i].imshow(dog[i][0][0]) for i in range(0,5)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXrtpTJa5vP-"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc,  \n",
    "                                     batch_size=30) \n",
    "val_generator = val_datagen.flow(validation_imgs,   \n",
    "                                 validation_labels_enc,   \n",
    "                                 batch_size=20) \n",
    " \n",
    "input_shape = (150, 150, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYPq3J6R5vTC"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers \n",
    " \n",
    "model = Sequential() \n",
    "# convolution and pooling layers \n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',  \n",
    "                 input_shape=input_shape)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    " \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    " \n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-OxB7RT5vV6"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,  \n",
    "                              steps_per_epoch=100, epochs=100, \n",
    "                              validation_data=val_generator,  \n",
    "                              validation_steps=50, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH6IjTdR5vZc"
   },
   "outputs": [],
   "source": [
    "model.save('cats_dogs_cnn_img_aug.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8S_eqVI5vcJ"
   },
   "outputs": [],
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKJr7vw05vfU"
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16 \n",
    "from keras.models import Model \n",
    "import keras \n",
    " \n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet',  \n",
    "                                     input_shape=input_shape) \n",
    " \n",
    "output = vgg.layers[-1].output \n",
    "output = keras.layers.Flatten()(output) \n",
    "vgg_model = Model(vgg.input, output) \n",
    "vgg_model.trainable = False \n",
    " \n",
    "for layer in vgg_model.layers: \n",
    "    layer.trainable = False \n",
    " \n",
    "vgg_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPZbB-2m5vhw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('max_colwidth', -1) \n",
    " \n",
    "layers = [(layer, layer.name, layer.trainable) for layer in \n",
    "           vgg_model.layers] \n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer  \n",
    "                               Trainable']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fytQqYS45vld"
   },
   "outputs": [],
   "source": [
    "print(\"Trainable layers:\", vgg_model.trainable_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMd7SM7S5vpD"
   },
   "outputs": [],
   "source": [
    "bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1]) print(bottleneck_feature_example.shape) \n",
    "plt.imshow(bottleneck_feature_example[0][:,:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdMrazxt5vtr"
   },
   "outputs": [],
   "source": [
    "def get_bottleneck_features(model, input_imgs): \n",
    "    features = model.predict(input_imgs, verbose=0) \n",
    "    return features \n",
    "\n",
    "train_features_vgg = get_bottleneck_features(vgg_model, \n",
    "                                             train_imgs_scaled) \n",
    "validation_features_vgg = get_bottleneck_features(vgg_model,      \n",
    "                                                validation_imgs_scaled) \n",
    "\n",
    "print('Train Bottleneck Features:', train_features_vgg.shape, \n",
    "      '\\tValidation Bottleneck Features:',  \n",
    "       validation_features_vgg.shape) \n",
    "\n",
    "Train Bottleneck Features: (3000, 8192) Validation Bottleneck Features: \n",
    "     (1000, 8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1JXKdH15vsY"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers \n",
    "\n",
    "input_shape = vgg_model.output_shape[1] \n",
    "model = Sequential() \n",
    "model.add(InputLayer(input_shape=(input_shape,))) \n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape)) model.add(Dropout(0.3)) model.add(Dense(512, activation='relu')) model.add(Dropout(0.3)) model.add(Dense(1, activation='sigmoid')) model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsh7NcdL6cL4"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers \n",
    "\n",
    "input_shape = vgg_model.output_shape[1] \n",
    "model = Sequential() \n",
    "model.add(InputLayer(input_shape=(input_shape,))) \n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape)) model.add(Dropout(0.3)) model.add(Dense(512, activation='relu')) model.add(Dropout(0.3)) model.add(Dense(1, activation='sigmoid')) model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LvpILw06cO8"
   },
   "outputs": [],
   "source": [
    "model.save('cats_dogs_tlearn_basic_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpZVhTwU6cR-"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, \n",
    "                                   rotation_range=50,   \n",
    "                                   width_shift_range=0.2,  \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   horizontal_flip=True,  \n",
    "                                   fill_mode='nearest') \n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) \n",
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc, \n",
    "                                     batch_size=30) \n",
    "val_generator = val_datagen.flow(validation_imgs, \n",
    "                                 validation_labels_enc, \n",
    "                                 batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yz5NHq0z6cVC"
   },
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(vgg_model) \n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape)) model.add(Dropout(0.3)) model.add(Dense(512, activation='relu')) model.add(Dropout(0.3)) model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=2e-5), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6p1Wx3sM6cYV"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=100, \n",
    "                              epochs=100, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=50, \n",
    "                              verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_RAFimS6cby"
   },
   "outputs": [],
   "source": [
    "model.save('cats_dogs_tlearn_img_aug_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lq_SlTBR6cfR"
   },
   "outputs": [],
   "source": [
    "vgg_model.trainable = True \n",
    "set_trainable = False\n",
    " \n",
    "for layer in vgg_model.layers: \n",
    "    if layer.name in ['block5_conv1', 'block4_conv1']: \n",
    "        set_trainable = True \n",
    "    if set_trainable: \n",
    "        layer.trainable = True \n",
    "    else: \n",
    "        layer.trainable = False \n",
    "\n",
    "print(\"Trainable layers:\", vgg_model.trainable_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fragEKsj6y-v"
   },
   "outputs": [],
   "source": [
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers] pd.DataFrame(layers, columns=['Layer Type', 'Layer \n",
    "                               Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Zq_HuIC6zCW"
   },
   "outputs": [],
   "source": [
    "# data generators \n",
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,                  \n",
    "                                   rotation_range=50, \n",
    "                                   width_shift_range=0.2,  \n",
    "                                   height_shift_range=0.2,    \n",
    "                                   shear_range=0.2,  \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest') \n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc,  \n",
    "                                     batch_size=30) \n",
    "val_generator = val_datagen.flow(validation_imgs, \n",
    "                                 validation_labels_enc, \n",
    "                                 batch_size=20) \n",
    "\n",
    "# build model architecture \n",
    "model = Sequential() \n",
    "\n",
    "model.add(vgg_model) \n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape)) model.add(Dropout(0.3)) model.add(Dense(512, activation='relu')) model.add(Dropout(0.3)) model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-5), \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# model training \n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, \n",
    "                              epochs=100,  \n",
    "                              validation_data=val_generator,   \n",
    "                              validation_steps=50,  \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXPODNUd6zGN"
   },
   "outputs": [],
   "source": [
    "model.save('cats_dogs_tlearn_finetune_img_aug_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLg7Ri8U6zJ5"
   },
   "outputs": [],
   "source": [
    "import glob \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img \n",
    "from keras.models import load_model \n",
    "import model_evaluation_utils as meu \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35qPwtRU6zOB"
   },
   "outputs": [],
   "source": [
    "basic_cnn = load_model('cats_dogs_basic_cnn.h5') \n",
    "img_aug_cnn = load_model('cats_dogs_cnn_img_aug.h5') \n",
    "tl_cnn = load_model('cats_dogs_tlearn_basic_cnn.h5') \n",
    "tl_img_aug_cnn = load_model('cats_dogs_tlearn_img_aug_cnn.h5') tl_img_aug_finetune_cnn = \n",
    "              load_model('cats_dogs_tlearn_finetune_img_aug_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXOQSNJd6zRt"
   },
   "outputs": [],
   "source": [
    "# basic configurations \n",
    "IMG_DIM = (150, 150) \n",
    "input_shape = (150, 150, 3) \n",
    "num2class_label_transformer = lambda l: ['cat' if x == 0 else 'dog' for \n",
    "                                          x in l] \n",
    "class2num_label_transformer = lambda l: [0 if x == 'cat' else 1 for x   \n",
    "                                         in l] \n",
    "\n",
    "# load sample image \n",
    "sample_img_path = 'my_cat.jpg' \n",
    "sample_img = load_img(sample_img_path, target_size=IMG_DIM) \n",
    "sample_img_tensor = img_to_array(sample_img) \n",
    "sample_img_tensor = np.expand_dims(sample_img_tensor, axis=0) \n",
    "sample_img_tensor /= 255. \n",
    "print(sample_img_tensor.shape) \n",
    "plt.imshow(sample_img_tensor[0]) (1, 150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JT7691r6zVt"
   },
   "outputs": [],
   "source": [
    "cnn_prediction = num2class_label_transformer(basic_cnn.predict_classes(\n",
    "                                                  sample_img_tensor, \n",
    "                                                  verbose=0)) \n",
    "cnn_img_aug_prediction = num2class_label_transformer(img_aug_cnn.predict_classes(\n",
    "                                                     sample_img_tensor,   \n",
    "                                                     verbose=0)) \n",
    "tlearn_cnn_prediction = num2class_label_transformer(tl_cnn.predict_classes(  \n",
    "                                    get_bottleneck_features(vgg_model,                                                             \n",
    "                                    sample_img_tensor),  \n",
    "                                    verbose=0)) \n",
    "tlearn_cnn_img_aug_prediction =\n",
    "num2class_label_transformer(  \n",
    "                      tl_img_aug_cnn.predict_classes(sample_img_tensor, \n",
    "                                                     verbose=0)) \n",
    "tlearn_cnn_finetune_img_aug_prediction =\n",
    "num2class_label_transformer(  \n",
    "             tl_img_aug_finetune_cnn.predict_classes(sample_img_tensor,  \n",
    "                                                     verbose=0)) \n",
    "\n",
    "print('Predictions for our sample image:\\n', \n",
    "      '\\nBasic CNN:', cnn_prediction, \n",
    "      '\\nCNN with Img Augmentation:', cnn_img_aug_prediction, \n",
    "      '\\nPre-trained CNN (Transfer Learning):', tlearn_cnn_prediction, \n",
    "      '\\nPre-trained CNN with Img Augmentation (Transfer Learning):',    \n",
    "      tlearn_cnn_img_aug_prediction, \n",
    "      '\\nPre-trained CNN with Fine-tuning & Img Augmentation (Transfer  \n",
    "       Learning):', tlearn_cnn_finetune_img_aug_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQAcU3gW6zcl"
   },
   "outputs": [],
   "source": [
    "tl_img_aug_finetune_cnn.layers[0].layers[1:9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v62DCWBB7LFp"
   },
   "outputs": [],
   "source": [
    "from keras import models \n",
    "\n",
    "# Extracts the outputs of the top 8 layers: \n",
    "layer_outputs = [layer.output for layer in  \n",
    "                     tl_img_aug_finetune_cnn.layers[0].layers[1:9]] \n",
    "\n",
    "# Creates a model that will return these outputs, given the model input: activation_model = models.Model(\n",
    "                       inputs=tl_img_aug_finetune_cnn.layers[0].layers[1].input,  \n",
    "                       outputs=layer_outputs) \n",
    "\n",
    "# This will return a list of 8 Numpy arrays \n",
    "# one array per layer activation \n",
    "activations = activation_model.predict(sample_img_tensor) \n",
    "print('Sample layer shape:', activations[0].shape) \n",
    "print('Sample convolution (activation map) shape:', \n",
    "                           activations[0][0, :, :, 1].shape) \n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize=(16, 6)) \n",
    "ax[0].imshow(activations[0][0, :, :, 10], cmap='bone') ax[1].imshow(activations[0][0, :, :, 25], cmap='bone') ax[2].imshow(activations[0][0, :, :, 40], cmap='bone') ax[3].imshow(activations[0][0, :, :, 55], cmap='bone') ax[4].imshow(activations[0][0, :, :, 63], cmap='bone') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2h7SJE3H7LI-"
   },
   "outputs": [],
   "source": [
    "IMG_DIM = (150, 150) \n",
    "test_files = glob.glob('test_data/*') \n",
    "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) \n",
    "                         for img in test_files] \n",
    "test_imgs = np.array(test_imgs) \n",
    "\n",
    "test_labels = [fn.split('/')[1].split('.')[0].strip() for fn in test_files] test_labels_enc = class2num_label_transformer(test_labels) \n",
    "test_imgs_scaled = test_imgs.astype('float32') \n",
    "test_imgs_scaled /= 255 \n",
    "\n",
    "print('Test dataset shape:', test_imgs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXU7p-B17LMa"
   },
   "outputs": [],
   "source": [
    "# Model 1 - Basic CNN \n",
    "predictions = basic_cnn.predict_classes(test_imgs_scaled, verbose=0) \n",
    "predictions = num2class_label_transformer(predictions) meu.display_model_performance_metrics(true_labels=test_labels,  \n",
    "                                      predicted_labels=predictions,  \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mn6q_dLA7LQT"
   },
   "outputs": [],
   "source": [
    "# Model 2 - Basic CNN with Image Augmentation \n",
    "predictions = img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0) predictions = num2class_label_transformer(predictions) meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=predictions,  \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMvDuCXI7LUA"
   },
   "outputs": [],
   "source": [
    "# Model 3 - Transfer Learning (basic feature extraction) \n",
    "test_bottleneck_features = get_bottleneck_features(vgg_model, test_imgs_scaled) predictions = tl_cnn.predict_classes(test_bottleneck_features, verbose=0) predictions = num2class_label_transformer(predictions) \n",
    "\n",
    "meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=predictions,  \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9v7CjidL6zaL"
   },
   "outputs": [],
   "source": [
    "# Model 4 - Transfer Learning with Image Augmentation \n",
    "predictions = tl_img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0) predictions = num2class_label_transformer(predictions) meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=predictions,  \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oX7rBs77cjl"
   },
   "outputs": [],
   "source": [
    "# Model 5 - Transfer Learning with Fine-tuning & Image Augmentation \n",
    "predictions = tl_img_aug_finetune_cnn.predict_classes(test_imgs_scaled, \n",
    "                                                      verbose=0) \n",
    "predictions = num2class_label_transformer(predictions) meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=predictions,  \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvpkq5hq7cnE"
   },
   "outputs": [],
   "source": [
    "# worst model - basic CNN \n",
    "meu.plot_model_roc_curve(basic_cnn, test_imgs_scaled, \n",
    "                         true_labels=test_labels_enc, class_names=[0, \n",
    "                                                                    1]) \n",
    "\n",
    "# best model - transfer learning with fine-tuning & image augmentation meu.plot_model_roc_curve(tl_img_aug_finetune_cnn, test_imgs_scaled, \n",
    "                         true_labels=test_labels_enc, class_names=[0, \n",
    "                                                                    1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9s9fSm0q7cqj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1tK2cIF7cuI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFjFxf3y7cyV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kR7SamLV7c5n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNgiuDZ47c2s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 2 : LeNet (modified) and VGG models in colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
